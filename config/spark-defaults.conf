# spark-defaults.conf
# Configurações padrão aplicadas a todos os jobs Spark submetidos pelo Airflow.
# Override via SparkMicroserviceOperator(conf={...}) por job.

# ── Conectividade S3 (s3a://) ─────────────────────────────────────────────────
spark.hadoop.fs.s3a.impl                        org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider    com.amazonaws.auth.InstanceProfileCredentialsProvider,com.amazonaws.auth.EnvironmentVariableCredentialsProvider
spark.hadoop.fs.s3a.fast.upload                 true
spark.hadoop.fs.s3a.multipart.size              128M
spark.hadoop.fs.s3a.connection.maximum          100

# ── Performance ───────────────────────────────────────────────────────────────
spark.sql.adaptive.enabled                      true
spark.sql.adaptive.coalescePartitions.enabled   true
spark.sql.adaptive.skewJoin.enabled             true
spark.serializer                                org.apache.spark.serializer.KryoSerializer
spark.sql.parquet.compression.codec             snappy

# ── Event Log (Spark History Server) ─────────────────────────────────────────
spark.eventLog.enabled                          true
spark.eventLog.dir                              s3a://spark-logs/event-logs

# ── Segurança ─────────────────────────────────────────────────────────────────
spark.authenticate                              false
spark.network.timeout                           800s
spark.executor.heartbeatInterval                60s